{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a23596c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:03.496971Z",
     "iopub.status.busy": "2024-12-18T10:12:03.496638Z",
     "iopub.status.idle": "2024-12-18T10:12:03.504792Z",
     "shell.execute_reply": "2024-12-18T10:12:03.504417Z"
    },
    "papermill": {
     "duration": 0.011649,
     "end_time": "2024-12-18T10:12:03.505650",
     "exception": false,
     "start_time": "2024-12-18T10:12:03.494001",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INTERACTIVE_MODE = False  # Set to True to run the notebook interactively\n",
    "\n",
    "import sys\n",
    "\n",
    "if INTERACTIVE_MODE:\n",
    "    sys.path.append(\"../src\")\n",
    "    %load_ext autoreload\n",
    "    %autoreload 3\n",
    "    from tqdm.notebook import tqdm\n",
    "else:\n",
    "    sys.path.append(\"./src\")\n",
    "    from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cf95fb3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:03.509112Z",
     "iopub.status.busy": "2024-12-18T10:12:03.508787Z",
     "iopub.status.idle": "2024-12-18T10:12:04.988606Z",
     "shell.execute_reply": "2024-12-18T10:12:04.988153Z"
    },
    "papermill": {
     "duration": 1.482854,
     "end_time": "2024-12-18T10:12:04.989972",
     "exception": false,
     "start_time": "2024-12-18T10:12:03.507118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch as th\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import textwrap\n",
    "from pathlib import Path\n",
    "from time import time\n",
    "import itertools\n",
    "import os\n",
    "from random import shuffle\n",
    "from IPython.display import display\n",
    "\n",
    "_ = th.set_grad_enabled(False)\n",
    "\n",
    "hf_token = \"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\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69c1f4b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:04.993699Z",
     "iopub.status.busy": "2024-12-18T10:12:04.993439Z",
     "iopub.status.idle": "2024-12-18T10:12:04.995679Z",
     "shell.execute_reply": "2024-12-18T10:12:04.995328Z"
    },
    "papermill": {
     "duration": 0.004842,
     "end_time": "2024-12-18T10:12:04.996469",
     "exception": false,
     "start_time": "2024-12-18T10:12:04.991627",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_name = \"obj_patch_translation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e40ca9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:04.999815Z",
     "iopub.status.busy": "2024-12-18T10:12:04.999496Z",
     "iopub.status.idle": "2024-12-18T10:12:05.002042Z",
     "shell.execute_reply": "2024-12-18T10:12:05.001693Z"
    },
    "papermill": {
     "duration": 0.004995,
     "end_time": "2024-12-18T10:12:05.002826",
     "exception": false,
     "start_time": "2024-12-18T10:12:04.997831",
     "status": "completed"
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# papermill parameters\n",
    "batch_size = 8\n",
    "model = \"meta-llama/Llama-2-7b-hf\"\n",
    "model_path = None\n",
    "trust_remote_code = False\n",
    "device = \"auto\"\n",
    "remote = False\n",
    "num_few_shot = 5\n",
    "exp_id = None\n",
    "extra_args = []\n",
    "use_tl = False\n",
    "paper_args_str = ''\n",
    "del_model = 'no'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e88f416e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:05.006147Z",
     "iopub.status.busy": "2024-12-18T10:12:05.005833Z",
     "iopub.status.idle": "2024-12-18T10:12:05.007943Z",
     "shell.execute_reply": "2024-12-18T10:12:05.007600Z"
    },
    "papermill": {
     "duration": 0.004593,
     "end_time": "2024-12-18T10:12:05.008751",
     "exception": false,
     "start_time": "2024-12-18T10:12:05.004158",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "model = \"meta-llama/Llama-3.2-3B\"\n",
    "paper_args_str = \"[[[\\\"hi_translit\\\", \\\"it\\\"], [\\\"ml_translit\\\", \\\"it\\\"], [\\\"ta_translit\\\", \\\"it\\\"], [\\\"te_translit\\\", \\\"it\\\"], [\\\"gu_translit\\\", \\\"it\\\"]], \\\"ml\\\", \\\"it\\\"]\"\n",
    "del_model = \"no\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4f7794a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:05.012145Z",
     "iopub.status.busy": "2024-12-18T10:12:05.011824Z",
     "iopub.status.idle": "2024-12-18T10:12:07.138257Z",
     "shell.execute_reply": "2024-12-18T10:12:07.137715Z"
    },
    "papermill": {
     "duration": 2.129249,
     "end_time": "2024-12-18T10:12:07.139368",
     "exception": false,
     "start_time": "2024-12-18T10:12:05.010119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from exp_tools import load_model\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "\n",
    "\n",
    "parser = ArgumentParser()\n",
    "parser.add_argument(\"--num-patches\", type=int, default=-1)\n",
    "pargs = parser.parse_args(extra_args)\n",
    "num_patches = pargs.num_patches\n",
    "\n",
    "if model_path is None:\n",
    "    model_path = model\n",
    "nn_model = load_model(\n",
    "    model_path,\n",
    "    trust_remote_code=trust_remote_code,\n",
    "    device_map=device,\n",
    "    use_tl=use_tl,\n",
    ")\n",
    "tokenizer = nn_model.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba823a2b",
   "metadata": {
    "papermill": {
     "duration": 0.001404,
     "end_time": "2024-12-18T10:12:07.142658",
     "exception": false,
     "start_time": "2024-12-18T10:12:07.141254",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24c3c2ee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:07.146341Z",
     "iopub.status.busy": "2024-12-18T10:12:07.146111Z",
     "iopub.status.idle": "2024-12-18T10:12:07.550466Z",
     "shell.execute_reply": "2024-12-18T10:12:07.549989Z"
    },
    "papermill": {
     "duration": 0.407357,
     "end_time": "2024-12-18T10:12:07.551324",
     "exception": false,
     "start_time": "2024-12-18T10:12:07.143967",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from exp_tools import (\n",
    "    run_prompts,\n",
    ")\n",
    "from interventions import (\n",
    "    object_lens,\n",
    "    collect_activations,\n",
    "    collect_activations_batched,\n",
    "    get_num_layers,\n",
    ")\n",
    "from prompt_tools import translation_prompts, get_obj_id\n",
    "from load_dataset import get_word_translation_dataset as get_translations\n",
    "\n",
    "from utils import ulist\n",
    "from display_utils import plot_topk_tokens, plot_results, plot_k_results, k_subplots\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "def object_patching_plot(\n",
    "    source_lang_pairs,\n",
    "    input_lang,\n",
    "    target_lang,\n",
    "    extra_langs=None,\n",
    "    batch_size=batch_size,\n",
    "    num_words=None,\n",
    "    num_pairs=200,\n",
    "    exp_id=exp_id,\n",
    "    k=4,\n",
    "    remote=remote,\n",
    "):\n",
    "    \"\"\"\n",
    "    Experiment 2 of the paper:\n",
    "    - For each source_lang_pairs, construct a prompt translating the same concept (e.g. DOG):\n",
    "    L1: \"CAT^L1\" - L2: \"CAT^L2\"\n",
    "    ...\n",
    "    L1: \"DOG^L1\n",
    "\n",
    "    - Collect activation at the last token of the prompt and generate a mean latent representation for each layer\n",
    "\n",
    "    - For each layer `j`: Run the target prompts which are translations from the input_lang to the target_lang. During the forward pass, patch at the last token of the concept to be translated with the mean latent representation of the source prompts from `j` to the last layer.\n",
    "\n",
    "    We plot both the probabilities you get from the mean latent and the probabilities you get from the first source_lang_pairs latent.\n",
    "    \"\"\"\n",
    "    source_lang_pairs = np.array(source_lang_pairs)\n",
    "    if extra_langs is None:\n",
    "        extra_langs = []\n",
    "    if isinstance(extra_langs, str):\n",
    "        extra_langs = [extra_langs]\n",
    "    model_name = model.split(\"/\")[-1]\n",
    "    global source_df, target_df, target_prompts, target_probs, latent_probs, source_prompts, _source_prompts, _target_prompts\n",
    "    if exp_id is None:\n",
    "        exp_id = str(int(time()))\n",
    "    else:\n",
    "        exp_id = str(exp_id)\n",
    "    source_df = get_translations(\n",
    "        \"en\",\n",
    "        ulist([*source_lang_pairs.flatten(), input_lang, target_lang, *extra_langs]),\n",
    "        num_words,\n",
    "    )\n",
    "    target_df = get_translations(\n",
    "        input_lang,\n",
    "        ulist([*source_lang_pairs.flatten(), target_lang, *extra_langs]),\n",
    "        num_words,\n",
    "    )\n",
    "\n",
    "    _source_prompts = list(\n",
    "        zip(\n",
    "            *[\n",
    "                translation_prompts(\n",
    "                    source_df,\n",
    "                    nn_model.tokenizer,\n",
    "                    inp_lang,\n",
    "                    targ_lang,\n",
    "                    [target_lang, *extra_langs],\n",
    "                    augment_tokens=False,\n",
    "                    n=num_few_shot,\n",
    "                )\n",
    "                for inp_lang, targ_lang in source_lang_pairs\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    _target_prompts = translation_prompts(\n",
    "        target_df,\n",
    "        nn_model.tokenizer,\n",
    "        input_lang,\n",
    "        target_lang,\n",
    "        [*extra_langs],  # [*list(zip(*source_lang_pairs))[1], *extra_langs],\n",
    "        augment_tokens=False,\n",
    "        n=num_few_shot,\n",
    "    )\n",
    "\n",
    "    collected_pairs = 0\n",
    "    source_prompts = []\n",
    "    target_prompts = []\n",
    "    source_target = list(itertools.product(source_df.iterrows(), target_df.iterrows()))\n",
    "    shuffle(source_target)\n",
    "\n",
    "    for (i, source_row), (j, target_row) in source_target:\n",
    "        if source_row[\"word_original\"] == target_row[\"word_original\"]:\n",
    "            continue\n",
    "        src_p = _source_prompts[i]\n",
    "        targ_p = deepcopy(_target_prompts[j])\n",
    "        latent_tokens = {f\"source_{target_lang}\": src_p[0].latent_tokens[target_lang]}\n",
    "        latent_tokens.update(**targ_p.latent_tokens)\n",
    "        targ_p.latent_tokens = latent_tokens\n",
    "        targ_p.latent_strings[f\"sources\"] = ulist(\n",
    "            sum([p.target_strings for p in src_p], [])\n",
    "        )\n",
    "        targ_p.latent_strings[f\"source_{target_lang}\"] = src_p[0].latent_strings[\n",
    "            target_lang\n",
    "        ]\n",
    "        for lang in extra_langs:\n",
    "            targ_p.latent_tokens[f\"src + tgt {lang}\"] = ulist(\n",
    "                targ_p.latent_tokens[lang] + src_p[0].latent_tokens[lang]\n",
    "            )\n",
    "            targ_p.latent_strings[f\"src + tgt {lang}\"] = ulist(\n",
    "                targ_p.latent_strings[lang] + src_p[0].latent_strings[lang]\n",
    "            )\n",
    "            del targ_p.latent_tokens[lang]\n",
    "        if targ_p.has_no_collisions():\n",
    "            source_prompts.append(src_p)\n",
    "            target_prompts.append(targ_p)\n",
    "            collected_pairs += 1\n",
    "        if collected_pairs >= num_pairs:\n",
    "            break\n",
    "    if collected_pairs < num_pairs:\n",
    "        print(\n",
    "            f\"Could only collect {collected_pairs} pairs for {source_lang_pairs.tolist()} - {input_lang} -> {target_lang}, skipping...\"\n",
    "        )\n",
    "        return\n",
    "    source_prompts = np.array(source_prompts)\n",
    "    source_prompts_str = np.array(\n",
    "        [['\"'.join(p.prompt.split('\"')[:-2]) for p in ps] for ps in source_prompts]\n",
    "    )\n",
    "    idx = get_obj_id(target_prompts[0].prompt, nn_model.tokenizer)\n",
    "\n",
    "    def object_patching(\n",
    "        nn_model, prompt_batch, scan, source_prompt_batch=None, only_first=False\n",
    "    ):\n",
    "        offset = object_patching.offset\n",
    "        batch_size = len(prompt_batch)\n",
    "        if source_prompt_batch is None:\n",
    "            source_prompt_batch = source_prompts_str[offset : offset + batch_size]\n",
    "        if only_first:\n",
    "            source_prompt_batch = source_prompt_batch[:, :1]\n",
    "        hiddens = collect_activations_batched(\n",
    "            nn_model, source_prompt_batch.flatten(), batch_size=batch_size, remote=remote\n",
    "        )\n",
    "        hiddens = hiddens.transpose(0, 1)  # (all_prompts, layer, hidden_size)\n",
    "        hiddens = hiddens.reshape(\n",
    "            batch_size, source_prompt_batch.shape[1], get_num_layers(nn_model), -1\n",
    "        ).mean(\n",
    "            dim=1\n",
    "        )  # (batch_size, num_layers, hidden_size)\n",
    "        hiddens = hiddens.transpose(0, 1)  # (num_layers, batch_size, hidden_size)\n",
    "        object_patching.offset += batch_size\n",
    "        return object_lens(\n",
    "            nn_model,\n",
    "            prompt_batch,\n",
    "            idx,\n",
    "            hiddens=hiddens,\n",
    "            scan=scan,\n",
    "            num_patches=num_patches,\n",
    "            remote=remote,\n",
    "        )\n",
    "\n",
    "    object_patching.offset = 0\n",
    "    target_probs, latent_probs = run_prompts(\n",
    "        nn_model, target_prompts, batch_size=batch_size, get_probs=object_patching, tqdm=tqdm\n",
    "    )\n",
    "    \n",
    "    display('111111111111111')\n",
    "     # Add these print statements\n",
    "    print(\"Target Probabilities Shape:\", target_probs.shape)\n",
    "    print(\"Target Probabilities Sample:\\n\", target_probs)  # First 5 examples\n",
    "    \n",
    "    print(\"\\nLatent Probabilities Keys:\", latent_probs.keys())\n",
    "    for key, probs in latent_probs.items():\n",
    "        print(f\"\\n{key} Shape:\", probs.shape)\n",
    "        print(f\"{key} Sample:\\n\", probs) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "62a5ca63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:12:07.555173Z",
     "iopub.status.busy": "2024-12-18T10:12:07.554728Z",
     "iopub.status.idle": "2024-12-18T10:15:07.807972Z",
     "shell.execute_reply": "2024-12-18T10:15:07.807573Z"
    },
    "papermill": {
     "duration": 180.255864,
     "end_time": "2024-12-18T10:15:07.808774",
     "exception": false,
     "start_time": "2024-12-18T10:12:07.552910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[['hi_translit', 'it'], ['ml_translit', 'it'], ['ta_translit', 'it'], ['te_translit', 'it'], ['gu_translit', 'it']], 'ml', 'it']\n",
      "source_lang: en\n",
      "df keys: ['fr', 'de', 'ru', 'en', 'zh', 'es', 'ja', 'ko', 'et', 'fi', 'nl', 'hi', 'word_original', 'it', 'hi_translit', 'ml_translit', 'ta_translit', 'te_translit', 'gu_translit', 'ml', 'ta', 'te', 'gu']\n",
      "tatget_lang: hi_translit\n",
      "tatget_lang: it\n",
      "tatget_lang: ml_translit\n",
      "tatget_lang: ta_translit\n",
      "tatget_lang: te_translit\n",
      "tatget_lang: gu_translit\n",
      "tatget_lang: ml\n",
      "tatget_lang: en\n",
      "Out_DF\n",
      "                                          hi_translit  \\\n",
      "0              [kitab, pustak, granth, sastra, pothi]   \n",
      "1                                [megha, badal, nimb]   \n",
      "2                                      [jhola, potli]   \n",
      "3                      [parvat, giri, shikhar, pahar]   \n",
      "4               [vastra, kapda, malmal, rakhi, dhoti]   \n",
      "..                                                ...   \n",
      "89  [official, karamchari, prashasanik, sarkari, n...   \n",
      "90             [office, karyalaya, kacheri, daakhana]   \n",
      "91                            [patthar, badal, shila]   \n",
      "92                      [shakti, bal, prabhav, sakti]   \n",
      "93                       [grishma, varsha, uttarayan]   \n",
      "\n",
      "                                                   it  \\\n",
      "0                                             [libro]   \n",
      "1                               [nube, nuvola, nembo]   \n",
      "2   [portamonete, borsello, borsetta, borsa, borse...   \n",
      "3                                   [montagna, monte]   \n",
      "4   [prodotto tessile, materia tessile, tessuto, s...   \n",
      "..                                                ...   \n",
      "89  [funzionario, funzionario pubblico, pubblico u...   \n",
      "90  [ente, organo, ufficio, agenzia, fonte, agenzi...   \n",
      "91  [musica rock, rock and roll, pietra, sasso, ro...   \n",
      "92  [potere politico, potere, potenza, forza, faco...   \n",
      "93                          [stagione estiva, estate]   \n",
      "\n",
      "                                          ml_translit  \\\n",
      "0                     [pustakam, grantham, saahityam]   \n",
      "1        [megham, meghangal, vayu, nivi, akashghatam]   \n",
      "2                                            [poocha]   \n",
      "3                           [malai, paadai, chithira]   \n",
      "4           [vadham, thooval, poochu, thira, veesham]   \n",
      "..                                                ...   \n",
      "89  [sarkari, vidhi, pramaanika, adhikarin, karyavah]   \n",
      "90         [office, karyalayam, dakshina, sambandham]   \n",
      "91                          [chithram, pathram, kaal]   \n",
      "92         [shakthi, balam, sakthi, vaibhavam, balam]   \n",
      "93                                          [visrjam]   \n",
      "\n",
      "                                          ta_translit  \\\n",
      "0         [sahithiyam, porul, kitab, pustakam, padam]   \n",
      "1                                             [meγam]   \n",
      "2               [pott, kutti, velicham, sakku, kaval]   \n",
      "3                    [malai, padi, kurinji, malaiyur]   \n",
      "4              [vastram, kaṭṭi, vaṭṭam, pōṭṭu, pāṭṭu]   \n",
      "..                                                ...   \n",
      "89    [oﬃcial, sarkārī, vazhvuthu, pūndhi, vazhvuthu]   \n",
      "90  [office, kārālikku, kārālikku, kārālikku, kārā...   \n",
      "91                                     [kallu, parai]   \n",
      "92          [valarchi, veliyam, suyam, balam, sakthi]   \n",
      "93                                           [kaalam]   \n",
      "\n",
      "                                          te_translit  \\\n",
      "0             [pustakam, grantham, sastramu, pustaka]   \n",
      "1   [megha, nimbham, meghalu, akash ghanam, vayu g...   \n",
      "2               [pocha, kottla, puchcha, bagu, jhola]   \n",
      "3             [parvata, giri, durgam, chilaka, malai]   \n",
      "4            [vastram, vastramu, pocha, kapa, pancha]   \n",
      "..                                                ...   \n",
      "89   [sarkari, pravarthaka, adhikarin, vidhi, niyama]   \n",
      "90  [office, karyalaya, dakshina, kanthara, samban...   \n",
      "91             [challa, badla, paruvu, bhoomi, patta]   \n",
      "92    [shakti, balam, sakthi, vaibhavam, balavardham]   \n",
      "93  [vasartham, grishma, uttarayana, simha masam, ...   \n",
      "\n",
      "                                          gu_translit  \\\n",
      "0             [kitab, pustak, granth, sastra, lekhan]   \n",
      "1            [megha, badal, dhuandhar, nirav, varsha]   \n",
      "2                                      [potli, jhola]   \n",
      "3                [parvat, giri, chauk, pash, shikhar]   \n",
      "4               [vadhu, vastra, kapda, poshak, dhoti]   \n",
      "..                                                ...   \n",
      "89  [official, sarkari, prashasanik, karyavah, niy...   \n",
      "90                [office, karyalaya, kacheri, dukan]   \n",
      "91                                  [chitra, patthar]   \n",
      "92                               [shakti, bal, sakti]   \n",
      "93                [grishma, varsha, uttarayan, garmi]   \n",
      "\n",
      "                                             ml  \\\n",
      "0        [പുസ്തകം, ഗ്രന്ഥം, പുസ്തകിക, ഗ്രന്ഥകം]   \n",
      "1       [മേഘം, മേഘാവൃതം, അഭ്രം, ജലാവൃതം, വായുഗ]   \n",
      "2        [സഞ്ചി, ബട്ട, പെട്ടി, പൈത്ത, കിസ്റ്റ്]   \n",
      "3          [കൊടുമുടി, മല, പർവതം, കുന്ന്, പർവതം]   \n",
      "4          [തുണി, വസ്ത്രം, ആടൈ, പട്ട്, കമ്പിളി]   \n",
      "..                                          ...   \n",
      "89     [ഔദ്യോഗികം, സർക്കാരി, ഉദ്യോഗപരമായ, അധിക]   \n",
      "90    [ഓഫീസ്, കാര്യാലയം, ജോലിസ്ഥലം, ഔദ്യോഗിക സ]   \n",
      "91             [കല്ല്, പാറ, ശില, പരിമളം, ശിഖരം]   \n",
      "92       [ശക്തി, അധികാരം, സാമർഥ്യം, ബലം, കഴിവ്]   \n",
      "93  [വേനൽ, അത്യുഷ്ണകാലം, ഗ്രീഷ്മം, വെളിച്ചെന്ന]   \n",
      "\n",
      "                                                   en word_original  \n",
      "0                                              [book]          book  \n",
      "1                                             [cloud]         cloud  \n",
      "2   [bag, purse, handbag, pocketbook, sack, paper ...           bag  \n",
      "3                                   [mountain, mount]      mountain  \n",
      "4                  [cloth, fabric, textile, material]         cloth  \n",
      "..                                                ...           ...  \n",
      "89  [official, functionary, referee, umpire, tenni...      official  \n",
      "90  [office, agency, authority, federal agency, go...        office  \n",
      "91  [rock, rock music, rock 'n' roll, rock'n'roll,...          rock  \n",
      "92  [power, political power, powerfulness, muscula...         power  \n",
      "93                [summer, summertime, summer season]        summer  \n",
      "\n",
      "[94 rows x 9 columns]\n",
      "source_lang: ml\n",
      "df keys: ['fr', 'de', 'ru', 'en', 'zh', 'es', 'ja', 'ko', 'et', 'fi', 'nl', 'hi', 'word_original', 'it', 'hi_translit', 'ml_translit', 'ta_translit', 'te_translit', 'gu_translit', 'ml', 'ta', 'te', 'gu']\n",
      "tatget_lang: hi_translit\n",
      "tatget_lang: it\n",
      "tatget_lang: ml_translit\n",
      "tatget_lang: ta_translit\n",
      "tatget_lang: te_translit\n",
      "tatget_lang: gu_translit\n",
      "tatget_lang: en\n",
      "Out_DF\n",
      "                                          hi_translit  \\\n",
      "0              [kitab, pustak, granth, sastra, pothi]   \n",
      "1                                [megha, badal, nimb]   \n",
      "2                                      [jhola, potli]   \n",
      "3                      [parvat, giri, shikhar, pahar]   \n",
      "4               [vastra, kapda, malmal, rakhi, dhoti]   \n",
      "..                                                ...   \n",
      "89  [official, karamchari, prashasanik, sarkari, n...   \n",
      "90             [office, karyalaya, kacheri, daakhana]   \n",
      "91                            [patthar, badal, shila]   \n",
      "92                      [shakti, bal, prabhav, sakti]   \n",
      "93                       [grishma, varsha, uttarayan]   \n",
      "\n",
      "                                                   it  \\\n",
      "0                                             [libro]   \n",
      "1                               [nube, nuvola, nembo]   \n",
      "2   [portamonete, borsello, borsetta, borsa, borse...   \n",
      "3                                   [montagna, monte]   \n",
      "4   [prodotto tessile, materia tessile, tessuto, s...   \n",
      "..                                                ...   \n",
      "89  [funzionario, funzionario pubblico, pubblico u...   \n",
      "90  [ente, organo, ufficio, agenzia, fonte, agenzi...   \n",
      "91  [musica rock, rock and roll, pietra, sasso, ro...   \n",
      "92  [potere politico, potere, potenza, forza, faco...   \n",
      "93                          [stagione estiva, estate]   \n",
      "\n",
      "                                          ml_translit  \\\n",
      "0                     [pustakam, grantham, saahityam]   \n",
      "1        [megham, meghangal, vayu, nivi, akashghatam]   \n",
      "2                                            [poocha]   \n",
      "3                           [malai, paadai, chithira]   \n",
      "4           [vadham, thooval, poochu, thira, veesham]   \n",
      "..                                                ...   \n",
      "89  [sarkari, vidhi, pramaanika, adhikarin, karyavah]   \n",
      "90         [office, karyalayam, dakshina, sambandham]   \n",
      "91                          [chithram, pathram, kaal]   \n",
      "92         [shakthi, balam, sakthi, vaibhavam, balam]   \n",
      "93                                          [visrjam]   \n",
      "\n",
      "                                          ta_translit  \\\n",
      "0         [sahithiyam, porul, kitab, pustakam, padam]   \n",
      "1                                             [meγam]   \n",
      "2               [pott, kutti, velicham, sakku, kaval]   \n",
      "3                    [malai, padi, kurinji, malaiyur]   \n",
      "4              [vastram, kaṭṭi, vaṭṭam, pōṭṭu, pāṭṭu]   \n",
      "..                                                ...   \n",
      "89    [oﬃcial, sarkārī, vazhvuthu, pūndhi, vazhvuthu]   \n",
      "90  [office, kārālikku, kārālikku, kārālikku, kārā...   \n",
      "91                                     [kallu, parai]   \n",
      "92          [valarchi, veliyam, suyam, balam, sakthi]   \n",
      "93                                           [kaalam]   \n",
      "\n",
      "                                          te_translit  \\\n",
      "0             [pustakam, grantham, sastramu, pustaka]   \n",
      "1   [megha, nimbham, meghalu, akash ghanam, vayu g...   \n",
      "2               [pocha, kottla, puchcha, bagu, jhola]   \n",
      "3             [parvata, giri, durgam, chilaka, malai]   \n",
      "4            [vastram, vastramu, pocha, kapa, pancha]   \n",
      "..                                                ...   \n",
      "89   [sarkari, pravarthaka, adhikarin, vidhi, niyama]   \n",
      "90  [office, karyalaya, dakshina, kanthara, samban...   \n",
      "91             [challa, badla, paruvu, bhoomi, patta]   \n",
      "92    [shakti, balam, sakthi, vaibhavam, balavardham]   \n",
      "93  [vasartham, grishma, uttarayana, simha masam, ...   \n",
      "\n",
      "                                          gu_translit  \\\n",
      "0             [kitab, pustak, granth, sastra, lekhan]   \n",
      "1            [megha, badal, dhuandhar, nirav, varsha]   \n",
      "2                                      [potli, jhola]   \n",
      "3                [parvat, giri, chauk, pash, shikhar]   \n",
      "4               [vadhu, vastra, kapda, poshak, dhoti]   \n",
      "..                                                ...   \n",
      "89  [official, sarkari, prashasanik, karyavah, niy...   \n",
      "90                [office, karyalaya, kacheri, dukan]   \n",
      "91                                  [chitra, patthar]   \n",
      "92                               [shakti, bal, sakti]   \n",
      "93                [grishma, varsha, uttarayan, garmi]   \n",
      "\n",
      "                                                   en  \\\n",
      "0                                              [book]   \n",
      "1                                             [cloud]   \n",
      "2   [bag, purse, handbag, pocketbook, sack, paper ...   \n",
      "3                                   [mountain, mount]   \n",
      "4                  [cloth, fabric, textile, material]   \n",
      "..                                                ...   \n",
      "89  [official, functionary, referee, umpire, tenni...   \n",
      "90  [office, agency, authority, federal agency, go...   \n",
      "91  [rock, rock music, rock 'n' roll, rock'n'roll,...   \n",
      "92  [power, political power, powerfulness, muscula...   \n",
      "93                [summer, summertime, summer season]   \n",
      "\n",
      "                                             ml word_original  \n",
      "0        [പുസ്തകം, ഗ്രന്ഥം, പുസ്തകിക, ഗ്രന്ഥകം]          book  \n",
      "1       [മേഘം, മേഘാവൃതം, അഭ്രം, ജലാവൃതം, വായുഗ]         cloud  \n",
      "2        [സഞ്ചി, ബട്ട, പെട്ടി, പൈത്ത, കിസ്റ്റ്]           bag  \n",
      "3          [കൊടുമുടി, മല, പർവതം, കുന്ന്, പർവതം]      mountain  \n",
      "4          [തുണി, വസ്ത്രം, ആടൈ, പട്ട്, കമ്പിളി]         cloth  \n",
      "..                                          ...           ...  \n",
      "89     [ഔദ്യോഗികം, സർക്കാരി, ഉദ്യോഗപരമായ, അധിക]      official  \n",
      "90    [ഓഫീസ്, കാര്യാലയം, ജോലിസ്ഥലം, ഔദ്യോഗിക സ]        office  \n",
      "91             [കല്ല്, പാറ, ശില, പരിമളം, ശിഖരം]          rock  \n",
      "92       [ശക്തി, അധികാരം, സാമർഥ്യം, ബലം, കഴിവ്]         power  \n",
      "93  [വേനൽ, അത്യുഷ്ണകാലം, ഗ്രീഷ്മം, വെളിച്ചെന്ന]        summer  \n",
      "\n",
      "[94 rows x 9 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:   0%|                                                                                                       | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62bcb5263b74268a309d9312a8f702b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a PreTrainedTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We detected that you are passing `past_key_values` as a tuple and this is deprecated and will be removed in v4.43. Please use an appropriate `Cache` class (https://huggingface.co/docs/transformers/v4.41.3/en/internal/generation_utils#transformers.Cache)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:   4%|███▊                                                                                           | 1/25 [00:11<04:35, 11.47s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:   8%|███████▌                                                                                       | 2/25 [00:18<03:20,  8.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  12%|███████████▍                                                                                   | 3/25 [00:25<02:54,  7.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  16%|███████████████▏                                                                               | 4/25 [00:32<02:37,  7.50s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  20%|███████████████████                                                                            | 5/25 [00:39<02:28,  7.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  24%|██████████████████████▊                                                                        | 6/25 [00:46<02:17,  7.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  28%|██████████████████████████▌                                                                    | 7/25 [00:53<02:08,  7.15s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  32%|██████████████████████████████▍                                                                | 8/25 [01:00<01:59,  7.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  36%|██████████████████████████████████▏                                                            | 9/25 [01:06<01:51,  6.97s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  40%|█████████████████████████████████████▌                                                        | 10/25 [01:14<01:46,  7.08s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  44%|█████████████████████████████████████████▎                                                    | 11/25 [01:21<01:37,  7.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  48%|█████████████████████████████████████████████                                                 | 12/25 [01:27<01:30,  6.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  52%|████████████████████████████████████████████████▉                                             | 13/25 [01:34<01:24,  7.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  56%|████████████████████████████████████████████████████▋                                         | 14/25 [01:41<01:16,  6.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  60%|████████████████████████████████████████████████████████▍                                     | 15/25 [01:48<01:09,  7.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  64%|████████████████████████████████████████████████████████████▏                                 | 16/25 [01:56<01:03,  7.05s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  68%|███████████████████████████████████████████████████████████████▉                              | 17/25 [02:02<00:55,  6.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  72%|███████████████████████████████████████████████████████████████████▋                          | 18/25 [02:09<00:48,  6.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  76%|███████████████████████████████████████████████████████████████████████▍                      | 19/25 [02:16<00:41,  7.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  80%|███████████████████████████████████████████████████████████████████████████▏                  | 20/25 [02:23<00:35,  7.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  84%|██████████████████████████████████████████████████████████████████████████████▉               | 21/25 [02:30<00:27,  6.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  88%|██████████████████████████████████████████████████████████████████████████████████▋           | 22/25 [02:37<00:21,  7.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  92%|██████████████████████████████████████████████████████████████████████████████████████▍       | 23/25 [02:44<00:13,  6.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts:  96%|██████████████████████████████████████████████████████████████████████████████████████████▏   | 24/25 [02:51<00:06,  6.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [02:58<00:00,  6.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running prompts: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 25/25 [02:58<00:00,  7.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'111111111111111'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Probabilities Shape: torch.Size([200, 28])\n",
      "Target Probabilities Sample:\n",
      " tensor([[1.2146e-02, 1.2680e-02, 1.2764e-02,  ..., 8.4668e-01, 8.4277e-01,\n",
      "         8.4424e-01],\n",
      "        [6.5804e-03, 6.3286e-03, 6.2599e-03,  ..., 8.4766e-01, 8.4326e-01,\n",
      "         8.4424e-01],\n",
      "        [2.4585e-01, 2.3523e-01, 2.3633e-01,  ..., 6.4990e-01, 6.5479e-01,\n",
      "         6.5283e-01],\n",
      "        ...,\n",
      "        [3.7849e-05, 3.8683e-05, 3.7611e-05,  ..., 8.6133e-01, 8.5742e-01,\n",
      "         8.5938e-01],\n",
      "        [6.2988e-01, 6.3965e-01, 6.3867e-01,  ..., 5.8984e-01, 5.8984e-01,\n",
      "         5.8984e-01],\n",
      "        [4.5443e-04, 4.7398e-04, 4.7970e-04,  ..., 5.4779e-02, 5.4535e-02,\n",
      "         5.3711e-02]], dtype=torch.float16)\n",
      "\n",
      "Latent Probabilities Keys: dict_keys(['source_it', 'src + tgt en'])\n",
      "\n",
      "source_it Shape: torch.Size([200, 28])\n",
      "source_it Sample:\n",
      " tensor([[1.6785e-01, 1.5027e-01, 1.5063e-01,  ..., 6.6662e-04, 6.7329e-04,\n",
      "         6.6900e-04],\n",
      "        [4.0259e-01, 4.0405e-01, 4.0527e-01,  ..., 2.6398e-03, 2.7027e-03,\n",
      "         2.7065e-03],\n",
      "        [7.6843e-02, 6.3721e-02, 6.2988e-02,  ..., 3.0727e-03, 2.9793e-03,\n",
      "         2.9602e-03],\n",
      "        ...,\n",
      "        [4.8853e-01, 4.8413e-01, 4.8560e-01,  ..., 9.7084e-04, 9.6750e-04,\n",
      "         9.5415e-04],\n",
      "        [1.0419e-01, 9.6741e-02, 9.7778e-02,  ..., 1.4305e-03, 1.4248e-03,\n",
      "         1.4162e-03],\n",
      "        [7.5342e-01, 7.4463e-01, 7.4219e-01,  ..., 2.9755e-04, 2.9588e-04,\n",
      "         2.9564e-04]], dtype=torch.float16)\n",
      "\n",
      "src + tgt en Shape: torch.Size([200, 28])\n",
      "src + tgt en Sample:\n",
      " tensor([[2.9163e-03, 2.8782e-03, 2.8725e-03,  ..., 2.8915e-03, 2.9545e-03,\n",
      "         2.9144e-03],\n",
      "        [4.6883e-03, 4.8714e-03, 4.8485e-03,  ..., 2.9182e-03, 3.0003e-03,\n",
      "         2.9583e-03],\n",
      "        [1.5549e-02, 1.5656e-02, 1.5602e-02,  ..., 5.5122e-03, 5.4321e-03,\n",
      "         5.4359e-03],\n",
      "        ...,\n",
      "        [1.1597e-02, 1.1902e-02, 1.1887e-02,  ..., 1.0824e-04, 1.1045e-04,\n",
      "         1.1039e-04],\n",
      "        [3.1433e-03, 2.9488e-03, 2.9602e-03,  ..., 1.2884e-03, 1.2884e-03,\n",
      "         1.2789e-03],\n",
      "        [1.4954e-03, 1.4658e-03, 1.4505e-03,  ..., 6.4075e-05, 6.4313e-05,\n",
      "         6.4671e-05]], dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "paper_args = json.loads(paper_args_str)\n",
    "print(paper_args)\n",
    "object_patching_plot(*paper_args, extra_langs=[\"en\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a47d37a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-18T10:15:07.816308Z",
     "iopub.status.busy": "2024-12-18T10:15:07.816038Z",
     "iopub.status.idle": "2024-12-18T10:15:07.818452Z",
     "shell.execute_reply": "2024-12-18T10:15:07.818134Z"
    },
    "papermill": {
     "duration": 0.006587,
     "end_time": "2024-12-18T10:15:07.819174",
     "exception": false,
     "start_time": "2024-12-18T10:15:07.812587",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if del_model == 'yes':\n",
    "    del model\n",
    "    del tokenizer\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 186.512448,
   "end_time": "2024-12-18T10:15:09.337995",
   "environment_variables": {},
   "exception": null,
   "input_path": "notebooks/obj_patch_translation_test.ipynb",
   "output_path": "out.ipynb",
   "parameters": {
    "del_model": "no",
    "model": "meta-llama/Llama-3.2-3B",
    "paper_args_str": "[[[\"hi_translit\", \"it\"], [\"ml_translit\", \"it\"], [\"ta_translit\", \"it\"], [\"te_translit\", \"it\"], [\"gu_translit\", \"it\"]], \"ml\", \"it\"]"
   },
   "start_time": "2024-12-18T10:12:02.825547",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "20ac0fbf32da40d88294c31ab47a1776": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2bf4bc8940ed47e4a836453c2c275b7b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "642357f099a04c63bc311ce39bead301": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_988204fb7b3c4779bae854297f92a44c",
       "placeholder": "​",
       "style": "IPY_MODEL_2bf4bc8940ed47e4a836453c2c275b7b",
       "tabbable": null,
       "tooltip": null,
       "value": " 2/2 [00:02&lt;00:00,  1.25s/it]"
      }
     },
     "892f988c81604988b9a7cb07418f92a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "9449dacd32f14c05920b2bb47ab11980": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "988204fb7b3c4779bae854297f92a44c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c62bcb5263b74268a309d9312a8f702b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d9861301da90467783e2c55727ae55b4",
        "IPY_MODEL_c9f5580d274a4a7995d076ea2d5cad9a",
        "IPY_MODEL_642357f099a04c63bc311ce39bead301"
       ],
       "layout": "IPY_MODEL_20ac0fbf32da40d88294c31ab47a1776",
       "tabbable": null,
       "tooltip": null
      }
     },
     "c9f5580d274a4a7995d076ea2d5cad9a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f66100ff94e6453293c950835ef87002",
       "max": 2.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_9449dacd32f14c05920b2bb47ab11980",
       "tabbable": null,
       "tooltip": null,
       "value": 2.0
      }
     },
     "d9861301da90467783e2c55727ae55b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f8124326243b4e4bbc0766df84327491",
       "placeholder": "​",
       "style": "IPY_MODEL_892f988c81604988b9a7cb07418f92a5",
       "tabbable": null,
       "tooltip": null,
       "value": "Loading checkpoint shards: 100%"
      }
     },
     "f66100ff94e6453293c950835ef87002": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f8124326243b4e4bbc0766df84327491": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}